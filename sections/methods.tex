\section{Methods}\label{sec:methods}


\begin{deluxetable*}{ccl}
\tabletypesize{\scriptsize}
\tablecaption{Glossary of notation. For constants, the order of magnitude of the constant is given as $\mathcal{O}(\cdot)$, for data structures, the shape (size) of the structure is given.
\label{tbl:definitions}}
\tablehead{\colhead{Symbol} & \colhead{Shape/Size} & \colhead{Description}}
\startdata
\cutinhead{Constants}
$ps_\mathrm{pupil}$ & $\mathcal{O}(10^-1$ \si{\meter\per\pixel}$)$ & pupil platescale \\
$\Delta_\mathrm{px}$ & $\mathcal{O}(1$ \si{\pixel}$)$ & translation between frames \\
$t$ & $\mathcal{O}(10^{-4}$ \si{\second}$)$ & time between frames \\
$f_\mathrm{RTC}$ & $\mathcal{O}(10^3$ \si{\hertz}$)$ & real-time controller loop rate \\
$N$ & $\mathcal{O}(10^2)$ & number of frames to skip (every $N$th frame) \\
$v$ & $\mathcal{O}(10$ \si{\meter\per\second}$)$ & measured wind speed in pupil \\
$\delta v$ & $\mathcal{O}(1$ \si{\meter\per\second}$)$ & wind speed resolution in pupil \\
$v_{\min}$ & $\mathcal{O}(1$ \si{\meter\per\second}$)$ & minimum detectable wind speed in pupil \\
$v_{\max}$ & $\mathcal{O}(10$ \si{\meter\per\second}$)$ & maximum detectable wind speed in pupil \\
$N_t$ & $\mathcal{O}(10^4)$ & number of frames in cube \\
$N_y, N_x$ & (50, 50) & number of pixels per axis per frame \\
\cutinhead{Data Structures}
cube & $(N_t, N_y, N_x)$ & stack of pseudo-open-loop AO telemetry frames \\
mask & $(N_y, N_x)$ & pupil geometry bitmask \\
$\chi$ & $(N_t - N, 2N_y - 1, 2N_x - 1)$ & cross-correlation maps for a given cube \\
\enddata
\end{deluxetable*}

As mentioned in \autoref{sec:windspeed}, we want to use AO telemetry directly for analyzing the dynamics of wind speed. AO telemetry describes any image or derived quantity from the AO system, starting with the wavefront sensor image. Wavefront sensors are located in the \textit{pupil plane}, which means the image is focused on the aperture of of the telescope (see \autoref{fig:pupil}). 

Most modern wavefront sensors (including the pyramid wavefront sensor on SCExAO) operate in ``closed-loop'' mode, which means the deformable mirror is upstream from the wavefront sensor. This means the wavefront sensor is measuring wavefront error \textit{residuals}; effectively the data has already been filtered of as much of the incident wavefront errors as possible. Since we are uniquely concerned with measuring these errors, we opt for using the pseudo-open-loop reconstruction, which emulates an ``open-loop'' AO system (where the wavefront sensor is upstream from the deformable mirror). This means the images are as close to the incident wavefront as possible, correcting for the temporal and spatial filtering imparted by the AO system. SCExAO has an additional complexity to consider: the Subaru telescope has another AO system (AO188; \citealp{2010SPIE.7736E..0NH}) that operates in addition to SCExAO. This means even in the pseudo-open-loop reconstruction SCExAO is seeing the residual wavefront from AO188.

During an observation, as light passes through Earth's atmosphere atmospheric cells reflect and refract the light, causing the amplitude and phase of the wavefront to become incoherent. The pseudo-open-loop reconstruction measures this wavefront in the column of space projected onto the telescope pupil. As wind moves the atmospheric cells in flows the corresponding wavefront errors will translate across the pupil. An example of this motion is shown in \autoref{fig:motion}.

\begin{figure}
    \centering
    \epsscale{0.8}
    \plotone{ao-column}
    \caption{An illustration of the lightpath from a faraway star as seen from the pupil plane of a ground-based telescope. The light enters Earth's atmosphere and will refract through the various atmospheric cells in the column of air above the telescope pupil. Wind can move these cells over time. This column appears projected in the pupil plane, as shown by the image on the right.}
    \label{fig:pupil}
\end{figure}


\begin{figure}
    \centering
    \epsscale{1}
    \plotone{motion}
    \caption{An example of the apparent motion wind is expected to have on wavefront errors in the pupil plane. Here a ``blob'' of wavefront errors, which corresponds to a particular atmospheric cell in the column of air above the pupil, translates about 7 pixels between 400 frames, which corresponds to a wind speed of $\sim$\SI{6}{\meter\per\second} according to the SCExAO loop speed and pupil geometry.}
    \label{fig:motion}
\end{figure}

So, if we can consistently measure the offset between frames we can derive the wind speed. Before addressing how we measure the offsets between frames, let's discuss how we calculate the wind speed from pixel offsets. The SCExAO pupil is an image of the Subaru primary mirror, which is \SI{8.2}{\meter} in diameter. The pupil-plane images we use span this distance with $\sim$48 pixels, so the pupil platescale is approximately \SI{0.17}{\meter\per\pixel}. If there is precise timing information for each frame, we can use that to determine the time delay between frames-
\begin{equation}
    v = \Delta_\mathrm{px} \cdot \frac{ps_\mathrm{pupil}}{t}
\end{equation}
where $\Delta_\mathrm{px}$ is the offset measured in pixels, $ps_\mathrm{pupil}$ is the pupil platescale, and $t$ is the time between frames. We can also use the real-time controller loop rate $f_\mathrm{RTC}$ (e.g., \SI{2}{\kilo\hertz}) to find the average time between $N$ frames-
\begin{equation}
    v = \Delta_\mathrm{px} \cdot \frac{ps_\mathrm{pupil} \cdot f_\mathrm{RTC}}{N}
    \label{eqn:quantity}
\end{equation}

\subsection{Measuring offsets in images}\label{sec:algo}

The previous section derived a formula for wind speed above the telescope pupil but glossed over how to actually measure the offset (or translation) between frames. One of the obstacles to overcome in our data is the effect of the pupil geometry; the pupil shape is effectively a mask. Already this has an effect on our algorithm for deriving wind speeds: if we are measuring offsets between frames sufficiently far apart in time, it is possible that a blob has moved entirely across the pupil, which would be impossible to measure, giving us a maximum measurable wind speed for a given time step (or, equivalently, for the number of frames).
\begin{equation}
    v_{\max} = \frac{8.2\mathrm{ m} \cdot f_\mathrm{RTC}}{N}
    \label{eqn:max}
\end{equation}

One measure for determining how similar two images are is their cross-correlation \citep{1997ApOpt..36.8352F}.
\begin{equation}
    \chi_{i} = \sum_{j}{f_{i}g_{j}}
    \label{eqn:crosscorr}
\end{equation}
where $\chi$ is the cross-correlation map, and $f$ and $g$ are the images in question. The index of the maximum value of $\chi$ corresponds to the amount of translation between $f$ and $g$. 

As mentioned previously, the pupil geometry acts like a mask for our images, which needs to be addressed when using the cross-correlation for measuring offsets. Imagine, for any given frame, there will always be zero signal outside of the pupil, which means that two frames will have extremely high measures of similarity. Since the signal-to-noise ratio (S/N) of these regions is effectively infinite, we want to mask these regions out and let the signal from \textit{within} the pupil drive our cross-correlation. \citet{2012ITIP...21.2706P} derives an efficient cross-correlation algorithm using a bitmask for the two images. We use the implementation from \verb|scikit-image| \citep{2014arXiv1407.6245V} in conjunction with the pupil geometry bitmask stored on the SCExAO control computer.

One consequence of using our masked cross-correlation algorithm is that we can't measure offsets less than half-pixel between frames. The discrete pixels in our images ``bin'' the cross correlation map and any offset less than \SI{0.5}{\pixel} gets binned to \SI{0}{\pixel}. This gives us a natural minimum detectable wind speed
\begin{equation}
    v_{\min} = 0.5\mathrm{ px}\cdot\frac{ps_\mathrm{pupil} \cdot f_\mathrm{RTC}}{N}
    \label{eqn:min}
\end{equation}
In addition, we derive a finite resolution (the bin size) for the wind speed
\begin{equation}
    \delta v = 1\mathrm{ px} \cdot\frac{ps_\mathrm{pupil} \cdot f_\mathrm{RTC}}{N}
    \label{eqn:resolution}
\end{equation}

Combining \autoref{eqn:max} and \autoref{eqn:min} helps guide our choice of how far apart we should measure frames for offsets. SCExAO typically operates at \SI{2}{\kilo\hertz}, and we expect wind speeds to be between $\sim$\SIrange{0}{60}{\meter\per\second}. Using every 300th frame ($N=300$) would give a minimum detectable speed of \SI{0.6}{\meter\per\second} and maximum detectable speed of \SI{55}{\meter\per\second}. In practice, we found that using every 400th frame ($N=400$) worked well.

As mentioned with regards to the pupil geometry, any static signal between images will dominate the cross-correlation compared to any moving signal. To help alleviate this, we perform multiple pre-processing steps to our data before measuring the masked cross-correlation. The SCExAO control computer can save \textit{pseudo-open-loop} frames as a cube of images, with $\mathcal{O}(10^4)$ frames per cube (which only corresponds to tens of seconds due to high loop rate). Pseudo-open-loop frames are used because they represent the highest S/N of wavefront errors in the pupil plane and have already been processed and filtered by the SCExAO real-time controller to remove systematics (like the deformable mirror flat frames).

Our first pre-processing step is to subtract out a median frame from the data cube, which helps remove static structure that may corrupt the cross-correlation. Without this step, we find that even the most trivial of datasets cannot effectively retrieve offsets between frames; removing static signal is paramount to having a bias-free cross-correlation. Another step we take to remove further static signal is filtering low-order Zernike modes out of our data. We do this because we expect the translational signal to be high spatial frequency, and we need to remove as much non-translational signal as possible. Another spatial filter we apply is a Gaussian high-pass filter. We accomplish this by convolving a Gaussian with \SI{5}{\pixel} spatial standard deviation and 1 frame temporal standard deviation to our data, and then subtracting this output from the cube. We found this chain of pre-processing is sufficient for testbed data and is a promising start for on-sky data, which will be discussed in \autoref{sec:onsky}. The full algorithm is listed in Algorithm~\autoref{alg:windspeed}.

\begin{algorithm}
\caption{wind speed measurement}\label{alg:windspeed}
\begin{algorithmic}[0]
\State $\mathbf{cube:}$ pseudo-open-loop full frame data ($N_t$, $N_y$, $N_x$)
\State $\mathbf{mask:}$ pupil bitmask ($N_y$, $N_x$)
\Procedure{WindSpeed}{cube, $N$, $f$, $n_Z$=7, stds=(1, 5, 5)}
    \State tmp $\gets$ cube - project\_zernike(cube, $n_Z$) \Comment{Filter out low-order Zernike modes}
    \State tmp $\gets$ tmp - median(tmp) \Comment{Subtract median frame}
    \State tmp $\gets$ tmp - gaussian\_filter(tmp, stds) \Comment{Gaussian high-pass filter}
    \For{$k$ in 1..($N_t-N$)} \Comment{For each frame in cube}
        \State previous $\gets$ tmp[$k$]
        \State current $\gets$ tmp[$k+N$]
        \State $\chi$[$k$] = masked\_cross\_correlate(current, previous, mask)
        \State idx $\gets$ argmax($\chi$[$k$])
        \State offset $\gets$ idx - ($N_y$, $N_x$) + 1 \Comment{Have to correct for geometry of cross-correlation}
        \State speed[$k$] $\gets$ offset $\cdot ps_\mathrm{pupil} \cdot f / N$
    \EndFor
    \State $\mathbf{return}$ $\chi$, speed
\EndProcedure
\end{algorithmic}
\end{algorithm}
